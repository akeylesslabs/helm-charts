 {{/*
Copyright Akeyless, Inc. All Rights Reserved.
SPDX-License-Identifier: APACHE-2.0
*/}}

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "cache-ha.fullname" . }}-scripts
  namespace: {{ include "cache-ha.namespace" . }}
  labels: {{- include "cache-ha.labels" . | nindent 4 }}
  {{- if .Values.commonAnnotations }}
  annotations:
    {{- include "cache-ha.commonAnnotations" . | nindent 4 }}
  {{- end }}
data:
  start-cache.sh: |
    #!/bin/sh
    set -e
    set -u

    # Logging functions (Bitnami style)
    info() { echo "[INFO] $*"; }
    debug() { echo "[DEBUG] $*"; }
    error() { echo "[ERROR] $*" >&2; }

    # Cache configuration
    CACHE_PORT="{{ .Values.ports.cache }}"
    CACHE_BIND="0.0.0.0"
    CACHE_APPENDONLY="yes"
    CACHE_PROTECTED_MODE="no"

    # Get pod information
    POD_NAME="${POD_NAME:-$(hostname)}"
    POD_NAMESPACE="${POD_NAMESPACE:-default}"

    # Create cache configuration directory
    mkdir -p {{ .Values.paths.configDir }}
    
    info "Starting cache node: $POD_NAME"
    info "Cache port: $CACHE_PORT"
    info "Protected mode: $CACHE_PROTECTED_MODE"
    
    # Create cache configuration
    cat > {{ .Values.paths.configDir }}/{{ .Values.paths.configFile }} << EOF
    # User-supplied common configuration
    bind ${CACHE_BIND}
    appendonly ${CACHE_APPENDONLY}
    protected-mode ${CACHE_PROTECTED_MODE}
    # Configure replica announcement to use hostname only
    replica-announce-ip ${POD_NAME}.{{ include "cache-ha.fullname" . }}-cache-headless.${POD_NAMESPACE}.svc.cluster.local
    replica-announce-port {{ .Values.ports.cache }}
    # Set log level (suppress SSL errors when set to warning)
    loglevel {{ .Values.logLevel }}
    # Reduce connection timeouts to fail faster and retry more frequently
    timeout 0
    # Increase TCP keepalive to detect dead connections faster
    tcp-keepalive 60
    # Suppress startup connection errors during cluster formation
    tcp-backlog 511
    {{- if .Values.auth.enabled }}
    requirepass ${REDIS_PASSWORD}
    masterauth ${REDIS_PASSWORD}
    {{- end }}
    {{- if .Values.node.extraFlags }}
    {{- range .Values.node.extraFlags }}
    {{ . }}
    {{- end }}
    {{- end }}
    # End of common configuration
    EOF

    # Wait for DNS to stabilize before starting Redis (blocking with timeout)
    # This prevents hostname resolution errors during startup
    echo "Waiting for DNS to stabilize..."
    timeout=30
    retry_count=0
    while [ $retry_count -lt $timeout ]; do
      all_resolved=true
      max_cache=$(expr {{ .Values.node.replicaCount }} - 1)
      for i in $(seq 0 $max_cache); do
        if [ "$i" != "${POD_NAME##*-}" ]; then
          if ! nslookup "{{ include "cache-ha.fullname" . }}-cache-${i}.{{ include "cache-ha.fullname" . }}-cache-headless.${POD_NAMESPACE}.svc.cluster.local" >/dev/null 2>&1; then
            all_resolved=false
            break
          fi
        fi
      done
      if [ "$all_resolved" = "true" ]; then
        echo "DNS ready, starting Redis..."
        break
      fi
      sleep 1
      retry_count=$(expr $retry_count + 1)
    done
    if [ $retry_count -eq $timeout ]; then
      echo "DNS timeout reached, starting Redis anyway..."
    fi

    # Start cache
    echo "Starting cache server on port ${CACHE_PORT}"
    {{- if .Values.tls.enabled }}
    # Start Redis with TLS-only mode using command line args (Bitnami approach)
    redis-server --port 0 --tls-port {{ .Values.ports.cache }} --tls-cert-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCertFile }} --tls-key-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsKeyFile }} --tls-ca-cert-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCaCertFile }} --tls-replication yes{{- if .Values.tls.authClients }} --tls-auth-clients yes{{- end }} --include {{ .Values.paths.configDir }}/{{ .Values.paths.configFile }} &
    {{- else }}
    # Start Redis in plain mode
    redis-server --port {{ .Values.ports.cache }} --include {{ .Values.paths.configDir }}/{{ .Values.paths.configFile }} &
    {{- end }}

    # Wait for cache to start
    echo "Waiting for cache to start..."
    sleep 10
    
    # Let Sentinel handle master election - don't configure replication here
    # Sentinel will automatically configure master-replica relationships
    echo "Cache started - Sentinel will configure replication automatically"
    
    # Keep process in foreground
    wait

  start-sentinel.sh: |
    #!/bin/sh
    set -e
    set -u

    # Logging functions (Bitnami style)
    info() { echo "[INFO] $*"; }
    debug() { echo "[DEBUG] $*"; }
    error() { echo "[ERROR] $*" >&2; }
    warning() { echo "[WARNING] $*" >&2; }

    # Sentinel configuration
    SENTINEL_PORT="{{ .Values.ports.sentinel }}"
    SENTINEL_BIND="0.0.0.0"
    MASTER_SET="{{ .Values.sentinel.masterSet }}"
    QUORUM="{{ include "cache-ha.sentinelQuorum" . }}"
    DOWN_AFTER_MS="{{ .Values.sentinel.downAfterMilliseconds }}"
    FAILOVER_TIMEOUT="{{ .Values.sentinel.failoverTimeout }}"
    PARALLEL_SYNCS="{{ .Values.sentinel.parallelSyncs }}"

    # Get pod information
    POD_NAME="${POD_NAME:-$(hostname)}"
    POD_NAMESPACE="${POD_NAMESPACE:-default}"
    
    # DNS resolution with retry logic (POSIX sh compatible)
    get_full_hostname() {
        hostname="$1"
        full_hostname="${hostname}.{{ include "cache-ha.fullname" . }}-cache-headless.${POD_NAMESPACE}.svc.cluster.local"
        
        info "Resolving hostname: $full_hostname" >&2
        retry_count=0
        max_retries=15
        retry_delay=5
        
        while [ $retry_count -lt $max_retries ]; do
            if getent hosts "$full_hostname" | awk '{ print $1; exit }' | grep -q .; then
                info "Successfully resolved $full_hostname" >&2
                echo "$full_hostname"
                return 0
            fi
            
            next_attempt=$(expr $retry_count + 1)
            info "DNS resolution attempt $next_attempt/$max_retries for $full_hostname" >&2
            sleep $retry_delay
            retry_count=$(expr $retry_count + 1)
        done
        
        error "Failed to resolve $full_hostname after $max_retries attempts"
        # Continue anyway - Redis Sentinel can handle this
        echo "$full_hostname"
        return 0
    }
    
    # Cache Sentinel approach: Monitor all cache instances and let Sentinel elect master
    # Start by monitoring the first cache pod as potential master
    MASTER_HOST=$(get_full_hostname "{{ include "cache-ha.fullname" . }}-cache-0")

    # Create Sentinel configuration directory
    mkdir -p {{ .Values.paths.configDir }}
    
    info "Starting sentinel node: $POD_NAME"
    info "Sentinel port: $SENTINEL_PORT"
    info "Master set: $MASTER_SET"
    info "Quorum: $QUORUM"
    info "Master host: $MASTER_HOST"
    
    # Warn if quorum is below recommended minimum for safety
    SENTINEL_COUNT="{{ .Values.sentinel.replicaCount }}"
    min_recommended=$(expr $SENTINEL_COUNT / 2 + 1)
    if [ $QUORUM -lt $min_recommended ]; then
        warning "Quorum $QUORUM is below recommended minimum $min_recommended for $SENTINEL_COUNT sentinels. This may increase split-brain risk."
    fi
    
    # Create Sentinel configuration
    cat > {{ .Values.paths.configDir }}/{{ .Values.paths.sentinelConfigFile }} << EOF
    port ${SENTINEL_PORT}
    bind ${SENTINEL_BIND}
    sentinel announce-hostnames yes
    sentinel resolve-hostnames yes
    sentinel announce-port ${SENTINEL_PORT}
    sentinel announce-ip ${POD_NAME}.{{ include "cache-ha.fullname" . }}-sentinel-headless.${POD_NAMESPACE}.svc.cluster.local
    sentinel monitor ${MASTER_SET} ${MASTER_HOST} {{ .Values.ports.cache }} ${QUORUM}
    sentinel down-after-milliseconds ${MASTER_SET} ${DOWN_AFTER_MS}
    sentinel failover-timeout ${MASTER_SET} ${FAILOVER_TIMEOUT}
    sentinel parallel-syncs ${MASTER_SET} ${PARALLEL_SYNCS}
    {{- if .Values.auth.enabled }}
    sentinel auth-pass ${MASTER_SET} ${REDIS_PASSWORD}
    {{- end }}
    # Set log level to suppress DNS resolution errors
    loglevel {{ .Values.logLevel }}
    # Reduce connection timeouts to fail faster and retry more frequently
    timeout 0
    # Disable protected mode to avoid connection issues during startup
    protected-mode no
    # Increase TCP keepalive to detect dead connections faster
    tcp-keepalive 60
    # Suppress startup connection errors during cluster formation
    tcp-backlog 511
    # Enable hostname resolution to reduce DNS errors (Bitnami approach)
    sentinel resolve-hostnames yes
    sentinel announce-hostnames yes
    # Suppress DNS resolution errors during startup
    sentinel announce-ip ${POD_NAME}.{{ include "cache-ha.fullname" . }}-sentinel-headless.${POD_NAMESPACE}.svc.cluster.local
    EOF

    # Pre-populate known sentinels and replicas (Bitnami approach)
    # This eliminates DNS errors by resolving hostnames before Redis starts
    
    # Helper function to resolve hostname (non-blocking)
    resolve_hostname() {
      local hostname="$1"
      local ip=$(getent hosts "$hostname" | awk '{ print $1 }' | head -1)
      if [ -n "$ip" ]; then
        echo "$ip"
        return 0
      fi
      return 1
    }
    
    # Add known sentinels
    SENTINEL_COUNT="{{ .Values.sentinel.replicaCount }}"
    max_sentinel=$(expr $SENTINEL_COUNT - 1)
    current_sentinel=$(echo $POD_NAME | sed 's/.*-//')
    for i in $(seq 0 $max_sentinel); do
      if [ "$i" != "$current_sentinel" ]; then
        sentinel_name="{{ include "cache-ha.fullname" . }}-sentinel-${i}"
        sentinel_hostname="${sentinel_name}.{{ include "cache-ha.fullname" . }}-sentinel-headless.${POD_NAMESPACE}.svc.cluster.local"
        
        # Resolve hostname to IP with retry
        if sentinel_ip=$(resolve_hostname "$sentinel_hostname"); then
          hash=$(echo "${sentinel_name}-${i}-${POD_NAMESPACE}" | sha1sum | cut -d' ' -f1)
          echo "sentinel known-sentinel ${MASTER_SET} ${sentinel_hostname} {{ .Values.ports.sentinel }} ${hash}" >> {{ .Values.paths.configDir }}/{{ .Values.paths.sentinelConfigFile }}
          info "Added known sentinel: ${sentinel_hostname} -> ${sentinel_ip}"
        else
          warning "Could not resolve sentinel hostname: ${sentinel_hostname} (will be discovered dynamically)"
        fi
      fi
    done
    
    # Add known replicas (cache pods)
    REPLICA_COUNT="{{ .Values.node.replicaCount }}"
    max_replica=$(expr $REPLICA_COUNT - 1)
    for i in $(seq 0 $max_replica); do
      replica_name="{{ include "cache-ha.fullname" . }}-cache-${i}"
      replica_hostname="${replica_name}.{{ include "cache-ha.fullname" . }}-cache-headless.${POD_NAMESPACE}.svc.cluster.local"
      
      # Resolve hostname to IP with retry
      if replica_ip=$(resolve_hostname "$replica_hostname"); then
        echo "sentinel known-replica ${MASTER_SET} ${replica_hostname} {{ .Values.ports.cache }}" >> {{ .Values.paths.configDir }}/{{ .Values.paths.sentinelConfigFile }}
        info "Added known replica: ${replica_hostname} -> ${replica_ip}"
      else
        warning "Could not resolve replica hostname: ${replica_hostname} (will be discovered dynamically)"
      fi
    done


    # Quick DNS check for cache pods (informational only)
    echo "Checking cache DNS availability..."
    max_cache=$(expr {{ .Values.node.replicaCount }} - 1)
    for i in $(seq 0 $max_cache); do
      if nslookup "{{ include "cache-ha.fullname" . }}-cache-${i}.{{ include "cache-ha.fullname" . }}-cache-headless.${POD_NAMESPACE}.svc.cluster.local" >/dev/null 2>&1; then
        echo "Cache DNS ready for cache-${i}"
      else
        echo "Cache DNS not ready for cache-${i} (will retry internally)"
      fi
    done

    # Start Sentinel
    echo "Starting Cache Sentinel on port ${SENTINEL_PORT}"
    
    # Start Redis Sentinel normally
    # DNS errors during startup are normal in Kubernetes StatefulSets and don't affect functionality
    {{- if .Values.tls.enabled }}
    # Build TLS arguments for sh (POSIX compliant)
    set -- --port 0 --tls-port {{ .Values.ports.sentinel }} --tls-cert-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCertFile }} --tls-key-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsKeyFile }} --tls-ca-cert-file {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCaCertFile }} --tls-replication yes
    {{- if .Values.tls.authClients }}
    set -- "$@" --tls-auth-clients yes
    {{- end }}
    # Start Redis Sentinel with TLS
    exec redis-server {{ .Values.paths.configDir }}/{{ .Values.paths.sentinelConfigFile }} "$@" --sentinel
    {{- else }}
    # Start Redis Sentinel in plain mode
    exec redis-server {{ .Values.paths.configDir }}/{{ .Values.paths.sentinelConfigFile }} --sentinel
    {{- end }}

  prestop-cache.sh: |
    #!/bin/sh
    set -e
    set -u

    # Graceful shutdown
    echo "Stopping cache server gracefully"
    {{- if .Values.tls.enabled }}
    redis-cli --tls --cert {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCertFile }} --key {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsKeyFile }} --cacert {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCaCertFile }} -p {{ .Values.ports.cache }} SHUTDOWN SAVE
    {{- else }}
    redis-cli -p {{ .Values.ports.cache }} SHUTDOWN SAVE
    {{- end }}

  prestop-sentinel.sh: |
    #!/bin/sh
    set -e
    set -u

    # Graceful shutdown
    echo "Stopping Cache Sentinel gracefully"
    {{- if .Values.tls.enabled }}
    redis-cli --tls --cert {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCertFile }} --key {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsKeyFile }} --cacert {{ .Values.paths.tlsDir }}/{{ .Values.paths.tlsCaCertFile }} -p {{ .Values.ports.sentinel }} SHUTDOWN
    {{- else }}
    redis-cli -p {{ .Values.ports.sentinel }} SHUTDOWN
    {{- end }}
